# =============================================================================
# Conductor Settings
# =============================================================================
# This file contains non-secret configuration for the Conducator backend.
# Copy this file to the project root before running the server.
# Secrets go in conductor.secrets.yaml (never committed).

server:
  host: "0.0.0.0"
  port: 8000
  debug: false
  reload: false
  log_level: "info"
  allowed_origins:
    - "http://localhost:3000"
    - "http://localhost:5173"
    - "vscode-webview://*"

database:
  pool_size: 10
  max_overflow: 20
  pool_timeout: 30
  echo_sql: false

auth:
  token_expire_minutes: 60
  refresh_expire_days: 7
  require_email_verify: false

rooms:
  max_participants: 50
  max_rooms_per_user: 10
  session_timeout_minutes: 120
  enable_persistence: true

live_share:
  enabled: false                  # Disabled â€” replaced by git_workspace
  vscode_extension_id: "ms-vsliveshare.vsliveshare"
  host_timeout_seconds: 300

# =============================================================================
# Git Workspace Settings (NEW)
# =============================================================================
git_workspace:
  enabled: true
  workspaces_dir: "./workspaces"          # Local directory for git worktrees
  git_auth_mode: "token"                   # "token" (Mode A) or "delegate" (Mode B)
  credential_ttl_seconds: 3600             # Auto-expire credentials after 1 hour
  max_worktrees_per_repo: 20               # Safety cap on concurrent worktrees
  cleanup_on_room_close: true              # Remove worktree dir when room ends

# =============================================================================
# Code Search Settings (NEW)
# =============================================================================
code_search:
  enabled: true
  index_dir: "./cocoindex_data"            # Where sqlite-vec databases are stored
  embedding_backend: "local"               # "local" | "bedrock" | "openai"
  local_model_name: "all-MiniLM-L6-v2"    # SentenceTransformers model for local backend
  bedrock_model_id: "amazon.titan-embed-text-v2:0"   # If embedding_backend=bedrock
  openai_model_name: "text-embedding-3-small"         # If embedding_backend=openai
  chunk_size: 512                          # Max tokens per AST chunk
  top_k_results: 5                         # Default number of search results
