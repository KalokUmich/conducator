# Conductor Settings Configuration
# Copy this file to conductor.settings.yaml and customize your settings
#
# This file contains non-sensitive settings and CAN be committed to git.
# For API keys and secrets, use conductor.secrets.yaml (gitignored).
#
# Usage:
#   cp config/conductor.settings.yaml.example config/conductor.settings.yaml
#   # Then edit conductor.settings.yaml with your preferences

# =============================================================================
# Server Configuration
# =============================================================================
server:
  # Backend server host and port
  host: "localhost"
  port: 8000
  
  # Public URL for external access (set by ngrok or other tunnel service)
  # Leave empty to use localhost
  public_url: ""

# =============================================================================
# Ngrok Settings (non-secrets)
# =============================================================================
# Note: Ngrok authtoken is in conductor.secrets.yaml
ngrok:
  # Region (us, eu, ap, au, sa, jp, in)
  region: "eu"

  # Enable ngrok tunnel on startup
  enabled: true

# =============================================================================
# AI Summary Configuration
# =============================================================================
summary:
  # Enable AI-powered summarization feature
  enabled: true
  
  # Default model to use for summarization
  # Must match an id from ai_models below
  default_model: "claude-sonnet-4-anthropic"

# =============================================================================
# AI Provider Settings
# =============================================================================
# Enable/disable providers. Even if enabled here, providers need valid API keys
# in conductor.secrets.yaml to function. UI will show grayed out if unavailable.
ai_provider_settings:
  anthropic_enabled: true
  aws_bedrock_enabled: true
  openai_enabled: true

# =============================================================================
# AI Models Configuration
# =============================================================================
# Define available models for each provider.
# Only models for enabled providers with valid API keys will be usable.
#
# Note for AWS Bedrock:
# - Some models (like Claude Sonnet 4) only support cross-region inference
# - Use the inference profile ID format: us.anthropic.claude-sonnet-4-20250514-v1:0
# - Or use models that support single-region: anthropic.claude-3-haiku-20240307-v1:0
ai_models:
  - id: "claude-sonnet-4-anthropic"
    provider: "anthropic"
    model_name: "claude-sonnet-4-20250514"
    display_name: "Claude Sonnet 4 (Anthropic)"
    enabled: true

  - id: "claude-3-haiku-bedrock"
    provider: "aws_bedrock"
    model_name: "anthropic.claude-3-haiku-20240307-v1:0"
    display_name: "Claude 3 Haiku (Bedrock)"
    enabled: true

  - id: "claude-sonnet-4-5-bedrock"
    provider: "aws_bedrock"
    model_name: "eu.anthropic.claude-sonnet-4-5-20250929-v1:0"
    display_name: "Claude Sonnet 4.5 (Bedrock EU)"
    enabled: true

  - id: "claude-sonnet-4-6-bedrock"
    provider: "aws_bedrock"
    model_name: "eu.anthropic.claude-sonnet-4-6"
    display_name: "Claude Sonnet 4.6 (Bedrock EU)"
    enabled: true

  - id: "qwen3-coder-next-bedrock"
    provider: "aws_bedrock"
    model_name: "qwen.qwen3-coder-next"
    display_name: "Qwen3 Coder Next (Bedrock EU)"
    enabled: true

  - id: "qwen3-next-80b"
    provider: "aws_bedrock"
    model_name: "qwen.qwen3-next-80b-a3b"
    display_name: "Qwen3 Next 80B (Bedrock EU)"
    enabled: true

  - id: "gpt-4o"
    provider: "openai"
    model_name: "gpt-4o"
    display_name: "GPT-4o"
    enabled: true

  - id: "gpt-4o-mini"
    provider: "openai"
    model_name: "gpt-4o-mini"
    display_name: "GPT-4o Mini"
    enabled: true

# =============================================================================
# Prompt Configuration
# =============================================================================
# Controls how the code generation prompt is formatted.
# output_mode options:
#   "unified_diff"       - Provide changes as unified diff patches (default)
#   "direct_repo_edits"  - Provide complete file contents
#   "plan_then_diff"     - Provide implementation plan, then diffs
prompt:
  output_mode: "unified_diff"

# =============================================================================
# Session Configuration
# =============================================================================
session:
  # Session timeout in minutes (0 = no timeout)
  timeout_minutes: 0
  
  # Maximum participants per room
  max_participants: 10

# =============================================================================
# Change Limits Configuration
# =============================================================================
change_limits:
  max_files_per_request: 10
  max_lines_per_file: 500
  max_total_lines: 2000
  auto_apply:
    enabled: false
    max_lines: 50

# =============================================================================
# Logging Configuration
# =============================================================================
logging:
  # Log level (debug, info, warning, error)
  level: "info"
  
  # Enable DuckDB audit logging
  audit_enabled: true
  
  # Path to audit log database file
  audit_path: "backend/audit_logs.duckdb"

# =============================================================================
# AWS SSO Configuration
# =============================================================================
# Enable SSO login for user identification via AWS IAM Identity Center.
# Users can sign in before starting/joining a session.
sso:
  # Enable SSO login button in the extension
  enabled: true

  # Your AWS SSO portal start URL (from IAM Identity Center settings)
  start_url: "https://xxxx.awsapps.com/start"

  # AWS region where your IAM Identity Center is configured
  region: "eu-west-2"

# =============================================================================
# Google SSO Configuration
# =============================================================================
# Enable Google OAuth SSO login for user identification.
# Requires client_id and client_secret in conductor.secrets.yaml.
google_sso:
  # Enable Google SSO login button in the extension
  enabled: false

# =============================================================================
# Embedding Configuration
# =============================================================================
# Controls which cloud provider and model are used to generate vector
# embeddings for code symbols. Changing model triggers lazy re-embedding
# on next usage (the extension checks sha1 + model).
embedding:
  # Embedding provider (bedrock, openai, cohere)
  provider: "bedrock"

  # Provider-specific model ID for embeddings
  # Bedrock: cohere.embed-english-v3, cohere.embed-multilingual-v3, amazon.titan-embed-text-v2:0
  # OpenAI: text-embedding-3-small, text-embedding-3-large
  model: "cohere.embed-english-v3"

  # Expected vector dimensionality produced by the model
  # cohere.embed-english-v3: 1024, text-embedding-3-small: 1536
  dim: 1024

# =============================================================================
# RAG (Retrieval-Augmented Generation) Configuration
# =============================================================================
# Backend-centric FAISS vector store for semantic code retrieval.
# Requires a working embedding service (see embedding section above).
rag:
  # Enable the RAG pipeline
  enabled: true

  # Directory for persisted FAISS indices (relative to working directory)
  data_dir: "data/rag"

  # Maximum lines per code chunk (oversized symbols are split at blank lines)
  chunk_max_lines: 200

  # Default number of search results returned
  search_top_k: 10

  # Fraction of LLM context budget allocated to RAG-retrieved code
  token_budget_ratio: 0.6
